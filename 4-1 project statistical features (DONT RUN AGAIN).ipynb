{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted files to Accelerometer_CUA\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the name of the uploaded zip file\n",
    "uploaded_zip_file = 'Accelerometer.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the contents\n",
    "extracted_dir = 'Accelerometer_CUA'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.makedirs(extracted_dir)\n",
    "\n",
    "# Open the uploaded zip file\n",
    "zip_file_path = os.path.join(os.getcwd(), uploaded_zip_file)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the target directory\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "print(f\"Successfully extracted files to {extracted_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted files to Activity_CUA\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the name of the uploaded zip file\n",
    "uploaded_zip_file = 'Activity.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the contents\n",
    "extracted_dir = 'Activity_CUA'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.makedirs(extracted_dir)\n",
    "\n",
    "# Open the uploaded zip file\n",
    "zip_file_path = os.path.join(os.getcwd(), uploaded_zip_file)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the target directory\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "print(f\"Successfully extracted files to {extracted_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted files to Gyroscope_CUA\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the name of the uploaded zip file\n",
    "uploaded_zip_file = 'Gyroscope.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the contents\n",
    "extracted_dir = 'Gyroscope_CUA'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.makedirs(extracted_dir)\n",
    "\n",
    "# Open the uploaded zip file\n",
    "zip_file_path = os.path.join(os.getcwd(), uploaded_zip_file)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the target directory\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "print(f\"Successfully extracted files to {extracted_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATHWIK\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column labels updated for all CSV files in the folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = 'Accelerometer_CUA/Accelerometer'\n",
    "\n",
    "# Define column labels for Accelerometer data\n",
    "accelerometer_labels = ['Systime', 'Event Time', 'ActivityID', 'X', 'Y', 'Z', 'Phone_orientation']\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is empty before attempting to read\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            # Read the current CSV file\n",
    "            current_df = pd.read_csv(file_path)\n",
    "\n",
    "            # Label the columns according to the accelerometer description\n",
    "            current_df.columns = accelerometer_labels\n",
    "\n",
    "            # Save the DataFrame back to the same CSV file\n",
    "            current_df.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            print(f\"Warning: Empty file - {file_name}\")\n",
    "\n",
    "print(\"Column labels updated for all CSV files in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column labels updated for all CSV files in the folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = 'Gyroscope_CUA/Gyroscope'\n",
    "\n",
    "# Define column labels for Gyroscope data\n",
    "gyroscope_labels = ['Systime', 'EventTime', 'ActivityID', 'X', 'Y', 'Z', 'Phone_orientation']\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is empty before attempting to read\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            # Read the current CSV file\n",
    "            current_df = pd.read_csv(file_path)\n",
    "\n",
    "            # Label the columns according to the gyroscope description\n",
    "            current_df.columns = gyroscope_labels\n",
    "\n",
    "            # Save the DataFrame back to the same CSV file\n",
    "            current_df.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            print(f\"Warning: Empty file - {file_name}\")\n",
    "\n",
    "print(\"Column labels updated for all CSV files in the folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column labels updated for all CSV files in the folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = 'Activity_CUA/Activity'\n",
    "\n",
    "# Define column labels for Gyroscope data\n",
    "gyroscope_labels = ['ActivityID', 'SubjectID', 'Session_number', 'Start_time', 'End_time', 'Relative_Start_time', 'Relative_End_time','Gesture_scenario','TaskID','ContentID']\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is empty before attempting to read\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            # Read the current CSV file\n",
    "            current_df = pd.read_csv(file_path)\n",
    "\n",
    "            # Label the columns according to the gyroscope description\n",
    "            current_df.columns = gyroscope_labels\n",
    "\n",
    "            # Save the DataFrame back to the same CSV file\n",
    "            current_df.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            print(f\"Warning: Empty file - {file_name}\")\n",
    "\n",
    "print(\"Column labels updated for all CSV files in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X       ActivityID         Z  Phone_orientation      EventTime  \\\n",
      "0  0.267864  100669011000001 -1.016174                  0  6785142573000   \n",
      "1  0.215330  100669011000001 -0.844521                  0  6785152583000   \n",
      "2 -0.426079  100669011000001  1.282512                  0  6785162593000   \n",
      "3 -0.072082  100669011000001 -0.275500                  0  6785172602000   \n",
      "4 -0.034208  100669011000001 -0.409280                  0  6785182673000   \n",
      "\n",
      "          Y        Systime  \n",
      "0  0.128893  1396226205573  \n",
      "1 -0.536034  1396226205575  \n",
      "2 -0.471893  1396226205577  \n",
      "3  0.765720  1396226205600  \n",
      "4 -0.105680  1396226205604  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'Gyroscope_CUA/Gyroscope'\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Define the number of files to concatenate. \n",
    "# Example: Set this to len(csv_files) to concatenate all files\n",
    "files_to_concatenate = len(csv_files)\n",
    "\n",
    "# Ensure that the number of files to concatenate is not greater than the total available files\n",
    "files_to_concatenate = min(files_to_concatenate, len(csv_files))\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "Gyroscope_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the specified number of files and concatenate rows\n",
    "for i in range(files_to_concatenate):\n",
    "    file_path = os.path.join(folder_path, csv_files[i])\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure consistent columns\n",
    "    if Gyroscope_df.empty:\n",
    "        Gyroscope_df = df\n",
    "    else:\n",
    "        # Keep only columns that are present in both DataFrames\n",
    "        common_columns = list(set(Gyroscope_df.columns) & set(df.columns))\n",
    "        Gyroscope_df = pd.concat([Gyroscope_df[common_columns], df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(Gyroscope_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 X       ActivityID         Z  Phone_orientation         Y  \\\n",
       "0       -0.101754  100669011000001  6.092046                  0  7.472902   \n",
       "1       -0.121506  100669011000001  6.323685                  0  7.411850   \n",
       "2       -0.126893  100669011000001  6.293758                  0  7.313688   \n",
       "3       -0.083797  100669011000001  6.186019                  0  7.307702   \n",
       "4       -0.003591  100669011000001  6.066308                  0  7.389704   \n",
       "...           ...              ...       ...                ...       ...   \n",
       "1763585 -2.065597  186676063000001  5.989694                  0  8.057087   \n",
       "1763586 -2.062006  186676063000001  5.854422                  0  8.067862   \n",
       "1763587 -2.127248  186676063000001  5.513248                  0  8.082227   \n",
       "1763588 -2.097321  186676063000001  5.259462                  0  8.135497   \n",
       "1763589 -2.085948  186676063000001  5.042788                  0  8.185776   \n",
       "\n",
       "               Systime     Event Time  \n",
       "0        1396226205572  6785142543000  \n",
       "1        1396226205574  6785152552000  \n",
       "2        1396226205576  6785162562000  \n",
       "3        1396226205598  6785172572000  \n",
       "4        1396226205601  6785182643000  \n",
       "...                ...            ...  \n",
       "1763585  1399158883282   847019860000  \n",
       "1763586  1399158883292   847030542000  \n",
       "1763587  1399158883304   847041986000  \n",
       "1763588  1399158883318   847054193000  \n",
       "1763589  1399158883488   847059014000  \n",
       "\n",
       "[1763590 rows x 7 columns]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'Accelerometer_CUA/Accelerometer'\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "\n",
    "\n",
    "# Ensure that the number of files to concatenate is not greater than the total available files\n",
    "files_to_concatenate = min(files_to_concatenate, len(csv_files))\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "A_concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the specified number of files and concatenate rows\n",
    "for i in range(files_to_concatenate):\n",
    "    file_path = os.path.join(folder_path, csv_files[i])\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure consistent columns\n",
    "    if A_concatenated_df.empty:\n",
    "        A_concatenated_df = df\n",
    "    else:\n",
    "        # Keep only columns that are present in both DataFrames\n",
    "        common_columns = list(set(A_concatenated_df.columns) & set(df.columns))\n",
    "        A_concatenated_df = pd.concat([A_concatenated_df[common_columns], df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "A_concatenated_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TaskID</th>\n",
       "      <th>Relative_End_time</th>\n",
       "      <th>ContentID</th>\n",
       "      <th>ActivityID</th>\n",
       "      <th>End_time</th>\n",
       "      <th>Start_time</th>\n",
       "      <th>Session_number</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Relative_Start_time</th>\n",
       "      <th>Gesture_scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7157788</td>\n",
       "      <td>2</td>\n",
       "      <td>100669012000001</td>\n",
       "      <td>1396226578198</td>\n",
       "      <td>1396226421894</td>\n",
       "      <td>1</td>\n",
       "      <td>100669</td>\n",
       "      <td>7001484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7230371</td>\n",
       "      <td>2</td>\n",
       "      <td>100669012000002</td>\n",
       "      <td>1396226650781</td>\n",
       "      <td>1396226600720</td>\n",
       "      <td>1</td>\n",
       "      <td>100669</td>\n",
       "      <td>7180310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7233466</td>\n",
       "      <td>2</td>\n",
       "      <td>100669012000002</td>\n",
       "      <td>1396226653876</td>\n",
       "      <td>1396226600720</td>\n",
       "      <td>1</td>\n",
       "      <td>100669</td>\n",
       "      <td>7180310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7317238</td>\n",
       "      <td>2</td>\n",
       "      <td>100669012000003</td>\n",
       "      <td>1396226737648</td>\n",
       "      <td>1396226672419</td>\n",
       "      <td>1</td>\n",
       "      <td>100669</td>\n",
       "      <td>7252008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7517052</td>\n",
       "      <td>3</td>\n",
       "      <td>100669013000001</td>\n",
       "      <td>1396226937462</td>\n",
       "      <td>1396226745978</td>\n",
       "      <td>1</td>\n",
       "      <td>100669</td>\n",
       "      <td>7325568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TaskID  Relative_End_time  ContentID       ActivityID       End_time  \\\n",
       "0       7            7157788          2  100669012000001  1396226578198   \n",
       "1       7            7230371          2  100669012000002  1396226650781   \n",
       "2       7            7233466          2  100669012000002  1396226653876   \n",
       "3       7            7317238          2  100669012000003  1396226737648   \n",
       "4       7            7517052          3  100669013000001  1396226937462   \n",
       "\n",
       "      Start_time  Session_number  SubjectID  Relative_Start_time  \\\n",
       "0  1396226421894               1     100669              7001484   \n",
       "1  1396226600720               1     100669              7180310   \n",
       "2  1396226600720               1     100669              7180310   \n",
       "3  1396226672419               1     100669              7252008   \n",
       "4  1396226745978               1     100669              7325568   \n",
       "\n",
       "   Gesture_scenario  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'Activity_CUA/Activity'\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "\n",
    "\n",
    "# Ensure that the number of files to concatenate is not greater than the total available files\n",
    "files_to_concatenate = min(files_to_concatenate, len(csv_files))\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "Act_concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the specified number of files and concatenate rows\n",
    "for i in range(files_to_concatenate):\n",
    "    file_path = os.path.join(folder_path, csv_files[i])\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure consistent columns\n",
    "    if Act_concatenated_df.empty:\n",
    "        Act_concatenated_df = df\n",
    "    else:\n",
    "        # Keep only columns that are present in both DataFrames\n",
    "        common_columns = list(set(Act_concatenated_df.columns) & set(df.columns))\n",
    "        Act_concatenated_df = pd.concat([Act_concatenated_df[common_columns], df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "Act_concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     TaskID  Relative_End_time  ContentID       ActivityID       End_time  \\\n",
      "0         7            7157788          2  100669012000001  1396226578198   \n",
      "1         7            7230371          2  100669012000002  1396226650781   \n",
      "2         7            7233466          2  100669012000002  1396226653876   \n",
      "3         7            7317238          2  100669012000003  1396226737648   \n",
      "4         7            7517052          3  100669013000001  1396226937462   \n",
      "..      ...                ...        ...              ...            ...   \n",
      "117       7            6813498          3  186676053000002  1399075996157   \n",
      "118       7            6821802          3  186676053000003  1399076004460   \n",
      "119       7            6834790          3  186676053000004  1399076017448   \n",
      "120       3             482315          2  186676062000001  1399158518576   \n",
      "121       3             847062          3  186676063000001  1399158883323   \n",
      "\n",
      "        Start_time  Session_number  SubjectID  Relative_Start_time  \\\n",
      "0    1396226421894               1     100669              7001484   \n",
      "1    1396226600720               1     100669              7180310   \n",
      "2    1396226600720               1     100669              7180310   \n",
      "3    1396226672419               1     100669              7252008   \n",
      "4    1396226745978               1     100669              7325568   \n",
      "..             ...             ...        ...                  ...   \n",
      "117  1399075988761               5     186676              6806102   \n",
      "118  1399076000278               5     186676              6817620   \n",
      "119  1399076014044               5     186676              6831385   \n",
      "120  1399158333135               6     186676               296874   \n",
      "121  1399158518621               6     186676               482360   \n",
      "\n",
      "     Gesture_scenario  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n",
      "..                ...  \n",
      "117                 1  \n",
      "118                 1  \n",
      "119                 1  \n",
      "120                 1  \n",
      "121                 1  \n",
      "\n",
      "[122 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Act_concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                X       ActivityID         Z  Phone_orientation         Y  \\\n",
      "0       -0.101754  100669011000001  6.092046                  0  7.472902   \n",
      "1       -0.121506  100669011000001  6.323685                  0  7.411850   \n",
      "2       -0.126893  100669011000001  6.293758                  0  7.313688   \n",
      "3       -0.083797  100669011000001  6.186019                  0  7.307702   \n",
      "4       -0.003591  100669011000001  6.066308                  0  7.389704   \n",
      "...           ...              ...       ...                ...       ...   \n",
      "1763585 -2.065597  186676063000001  5.989694                  0  8.057087   \n",
      "1763586 -2.062006  186676063000001  5.854422                  0  8.067862   \n",
      "1763587 -2.127248  186676063000001  5.513248                  0  8.082227   \n",
      "1763588 -2.097321  186676063000001  5.259462                  0  8.135497   \n",
      "1763589 -2.085948  186676063000001  5.042788                  0  8.185776   \n",
      "\n",
      "               Systime     Event Time  \n",
      "0        1396226205572  6785142543000  \n",
      "1        1396226205574  6785152552000  \n",
      "2        1396226205576  6785162562000  \n",
      "3        1396226205598  6785172572000  \n",
      "4        1396226205601  6785182643000  \n",
      "...                ...            ...  \n",
      "1763585  1399158883282   847019860000  \n",
      "1763586  1399158883292   847030542000  \n",
      "1763587  1399158883304   847041986000  \n",
      "1763588  1399158883318   847054193000  \n",
      "1763589  1399158883488   847059014000  \n",
      "\n",
      "[1763590 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(A_concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gyroscope_df.drop([ 'Phone_orientation'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                X       ActivityID         Z      EventTime         Y  \\\n",
      "0        0.267864  100669011000001 -1.016174  6785142573000  0.128893   \n",
      "1        0.215330  100669011000001 -0.844521  6785152583000 -0.536034   \n",
      "2       -0.426079  100669011000001  1.282512  6785162593000 -0.471893   \n",
      "3       -0.072082  100669011000001 -0.275500  6785172602000  0.765720   \n",
      "4       -0.034208  100669011000001 -0.409280  6785182673000 -0.105680   \n",
      "...           ...              ...       ...            ...       ...   \n",
      "1763333 -0.050091  186676063000001 -0.027184   847019891000 -0.228158   \n",
      "1763334 -0.017410  186676063000001 -0.021991   847030572000 -0.153327   \n",
      "1763335  0.046731  186676063000001 -0.018631   847042016000 -0.099266   \n",
      "1763336  0.107512  186676063000001 -0.014966   847054193000 -0.032070   \n",
      "1763337  0.132863  186676063000001 -0.007636   847059014000  0.031154   \n",
      "\n",
      "               Systime  \n",
      "0        1396226205573  \n",
      "1        1396226205575  \n",
      "2        1396226205577  \n",
      "3        1396226205600  \n",
      "4        1396226205604  \n",
      "...                ...  \n",
      "1763333  1399158883282  \n",
      "1763334  1399158883293  \n",
      "1763335  1399158883305  \n",
      "1763336  1399158883319  \n",
      "1763337  1399158883489  \n",
      "\n",
      "[1763338 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Gyroscope_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_concatenated_df.drop(['Phone_orientation'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                X       ActivityID         Z         Y        Systime  \\\n",
      "0       -0.101754  100669011000001  6.092046  7.472902  1396226205572   \n",
      "1       -0.121506  100669011000001  6.323685  7.411850  1396226205574   \n",
      "2       -0.126893  100669011000001  6.293758  7.313688  1396226205576   \n",
      "3       -0.083797  100669011000001  6.186019  7.307702  1396226205598   \n",
      "4       -0.003591  100669011000001  6.066308  7.389704  1396226205601   \n",
      "...           ...              ...       ...       ...            ...   \n",
      "1763585 -2.065597  186676063000001  5.989694  8.057087  1399158883282   \n",
      "1763586 -2.062006  186676063000001  5.854422  8.067862  1399158883292   \n",
      "1763587 -2.127248  186676063000001  5.513248  8.082227  1399158883304   \n",
      "1763588 -2.097321  186676063000001  5.259462  8.135497  1399158883318   \n",
      "1763589 -2.085948  186676063000001  5.042788  8.185776  1399158883488   \n",
      "\n",
      "            Event Time  \n",
      "0        6785142543000  \n",
      "1        6785152552000  \n",
      "2        6785162562000  \n",
      "3        6785172572000  \n",
      "4        6785182643000  \n",
      "...                ...  \n",
      "1763585   847019860000  \n",
      "1763586   847030542000  \n",
      "1763587   847041986000  \n",
      "1763588   847054193000  \n",
      "1763589   847059014000  \n",
      "\n",
      "[1763590 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(A_concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X       ActivityID         Z         Y        Systime  \\\n",
      "0 -0.101754  100669011000001  6.092046  7.472902  1396226205572   \n",
      "1 -0.121506  100669011000001  6.323685  7.411850  1396226205574   \n",
      "2 -0.126893  100669011000001  6.293758  7.313688  1396226205576   \n",
      "3 -0.083797  100669011000001  6.186019  7.307702  1396226205598   \n",
      "4 -0.003591  100669011000001  6.066308  7.389704  1396226205601   \n",
      "\n",
      "      Event Time      ID  \n",
      "0  6785142543000  100669  \n",
      "1  6785152552000  100669  \n",
      "2  6785162562000  100669  \n",
      "3  6785172572000  100669  \n",
      "4  6785182643000  100669  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named as A_concatenated_df\n",
    "A_concatenated_df = A_concatenated_df# your DataFrame\n",
    "\n",
    "# Extract the first 6 digits of ActivityID and create a new column 'ID'\n",
    "A_concatenated_df['ID'] = A_concatenated_df['ActivityID'].astype(str).str[:6]\n",
    "\n",
    "print(A_concatenated_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_concatenated_df.drop(['ActivityID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                X         Z         Y        Systime     Event Time      ID\n",
      "0       -0.101754  6.092046  7.472902  1396226205572  6785142543000  100669\n",
      "1       -0.121506  6.323685  7.411850  1396226205574  6785152552000  100669\n",
      "2       -0.126893  6.293758  7.313688  1396226205576  6785162562000  100669\n",
      "3       -0.083797  6.186019  7.307702  1396226205598  6785172572000  100669\n",
      "4       -0.003591  6.066308  7.389704  1396226205601  6785182643000  100669\n",
      "...           ...       ...       ...            ...            ...     ...\n",
      "1763585 -2.065597  5.989694  8.057087  1399158883282   847019860000  186676\n",
      "1763586 -2.062006  5.854422  8.067862  1399158883292   847030542000  186676\n",
      "1763587 -2.127248  5.513248  8.082227  1399158883304   847041986000  186676\n",
      "1763588 -2.097321  5.259462  8.135497  1399158883318   847054193000  186676\n",
      "1763589 -2.085948  5.042788  8.185776  1399158883488   847059014000  186676\n",
      "\n",
      "[1763590 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(A_concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X       ActivityID         Z      EventTime         Y  \\\n",
      "0  0.267864  100669011000001 -1.016174  6785142573000  0.128893   \n",
      "1  0.215330  100669011000001 -0.844521  6785152583000 -0.536034   \n",
      "2 -0.426079  100669011000001  1.282512  6785162593000 -0.471893   \n",
      "3 -0.072082  100669011000001 -0.275500  6785172602000  0.765720   \n",
      "4 -0.034208  100669011000001 -0.409280  6785182673000 -0.105680   \n",
      "\n",
      "         Systime      ID  \n",
      "0  1396226205573  100669  \n",
      "1  1396226205575  100669  \n",
      "2  1396226205577  100669  \n",
      "3  1396226205600  100669  \n",
      "4  1396226205604  100669  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named as A_concatenated_df\n",
    "Gyroscope_df = Gyroscope_df# your DataFrame\n",
    "\n",
    "# Extract the first 6 digits of ActivityID and create a new column 'ID'\n",
    "Gyroscope_df['ID'] = Gyroscope_df['ActivityID'].astype(str).str[:6]\n",
    "\n",
    "print(Gyroscope_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gyroscope_df.drop(['ActivityID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                X         Z      EventTime         Y        Systime      ID\n",
      "0        0.267864 -1.016174  6785142573000  0.128893  1396226205573  100669\n",
      "1        0.215330 -0.844521  6785152583000 -0.536034  1396226205575  100669\n",
      "2       -0.426079  1.282512  6785162593000 -0.471893  1396226205577  100669\n",
      "3       -0.072082 -0.275500  6785172602000  0.765720  1396226205600  100669\n",
      "4       -0.034208 -0.409280  6785182673000 -0.105680  1396226205604  100669\n",
      "...           ...       ...            ...       ...            ...     ...\n",
      "1763333 -0.050091 -0.027184   847019891000 -0.228158  1399158883282  186676\n",
      "1763334 -0.017410 -0.021991   847030572000 -0.153327  1399158883293  186676\n",
      "1763335  0.046731 -0.018631   847042016000 -0.099266  1399158883305  186676\n",
      "1763336  0.107512 -0.014966   847054193000 -0.032070  1399158883319  186676\n",
      "1763337  0.132863 -0.007636   847059014000  0.031154  1399158883489  186676\n",
      "\n",
      "[1763338 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Gyroscope_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (0.51.2)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (1.8.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.34.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (50.3.1.post20201107)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (20.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.24.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch>=1.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch>=1.0->librosa) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sathwik\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "pip install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID      XAVG  XABSOLDEV  XSTANDDEV       XVAR     XPEAK      YAVG  \\\n",
      "0      100669 -0.082516   0.164182   0.206978   0.042840  7.500000  7.736378   \n",
      "1      100669 -0.390614   0.244939   0.307240   0.094396  7.076923  8.159631   \n",
      "2      100669 -0.020219   0.217486   0.283649   0.080457  7.083333  7.931164   \n",
      "3      100669 -6.429293   3.159786   3.645151  13.287128  8.083333  2.313338   \n",
      "4      100669 -8.218121   0.307337   0.390145   0.152213  7.636364 -0.505051   \n",
      "...       ...       ...        ...        ...        ...       ...       ...   \n",
      "17630  186676 -0.595067   0.082840   0.105250   0.011078  4.130435  8.090516   \n",
      "17631  186676 -0.538755   0.079968   0.107981   0.011660  5.000000  7.984866   \n",
      "17632  186676 -0.532261   0.072167   0.094010   0.008838  4.850000  7.950934   \n",
      "17633  186676 -0.970717   0.774675   1.013359   1.026896  7.500000  8.187200   \n",
      "17634  186676 -2.511972   0.184835   0.259519   0.067350  6.333333  8.311597   \n",
      "\n",
      "       YABSOLDEV  YSTANDDEV       YVAR  ...  ZABSOLDEV  ZSTANDDEV      ZVAR  \\\n",
      "0       0.217195   0.284936   0.081189  ...   0.305009   0.389171  0.151454   \n",
      "1       0.196807   0.243487   0.059286  ...   0.605649   0.809402  0.655132   \n",
      "2       0.166542   0.194906   0.037988  ...   0.398571   0.543324  0.295201   \n",
      "3       3.093963   3.721532  13.849803  ...   0.979893   1.473493  2.171181   \n",
      "4       0.179238   0.226129   0.051134  ...   0.572986   0.705559  0.497814   \n",
      "...          ...        ...        ...  ...        ...        ...       ...   \n",
      "17630   0.098028   0.130230   0.016960  ...   0.317783   0.395714  0.156590   \n",
      "17631   0.105185   0.139599   0.019488  ...   0.292477   0.393625  0.154940   \n",
      "17632   0.076336   0.102343   0.010474  ...   0.206547   0.280032  0.078418   \n",
      "17633   0.133838   0.184788   0.034147  ...   0.307509   0.378116  0.142971   \n",
      "17634   0.055802   0.075242   0.005661  ...   0.225731   0.368826  0.136033   \n",
      "\n",
      "          ZPEAK     XYCOS     XYCOR     XZCOS     XZCOR     YZCOS     YZCOR  \n",
      "0      6.928571  1.363662  0.187595  1.376317 -0.104510  0.002498  0.279130  \n",
      "1      8.100000  1.789588 -0.213728  1.756277  0.182142  0.016371 -0.397572  \n",
      "2      7.545455  1.090211 -0.780695  1.007313  0.602255  0.007724 -0.710189  \n",
      "3      8.600000  1.055520  0.963843  1.791716  0.137434  0.435838  0.234248  \n",
      "4      6.846154  0.073093  0.786485  1.980571  0.687778  1.873920  0.407826  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "17630  7.333333  1.984571  0.006066  1.985141 -0.226196  0.003237 -0.792898  \n",
      "17631  6.769231  1.981129 -0.226607  1.974843  0.281096  0.003123 -0.757759  \n",
      "17632  8.454545  1.984866 -0.084838  1.983728 -0.001529  0.001591 -0.761217  \n",
      "17633  6.846154  1.699479 -0.485117  1.679908  0.212532  0.003195 -0.457619  \n",
      "17634  6.923077  1.994711 -0.050128  1.993927 -0.259685  0.003084 -0.384850  \n",
      "\n",
      "[17635 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def extract_ACC_features(df, window_size=100):\n",
    "    # List to store feature dictionaries for each window\n",
    "    features_list = []\n",
    "\n",
    "    for start in range(0, len(df), window_size):\n",
    "        window = df.iloc[start:start + window_size]\n",
    "\n",
    "        # Ensure the window has the correct size\n",
    "        if len(window) < window_size:\n",
    "            continue\n",
    "\n",
    "        features = {}\n",
    "        features['ID'] = window['ID'].iloc[0]\n",
    "\n",
    "        for axis in ['X', 'Y', 'Z']:\n",
    "            axis_data = window[axis].values  # Convert to numpy array\n",
    "\n",
    "            # Calculate features\n",
    "            features[f'{axis}AVG'] = np.mean(axis_data)\n",
    "            features[f'{axis}ABSOLDEV'] = np.mean(np.abs(axis_data - np.mean(axis_data)))\n",
    "            features[f'{axis}STANDDEV'] = np.std(axis_data)\n",
    "            features[f'{axis}VAR'] = np.var(axis_data)\n",
    "\n",
    "            # Peak times\n",
    "            peaks, _ = find_peaks(axis_data)\n",
    "            if len(peaks) >= 2:\n",
    "                peak_times = np.diff(peaks)\n",
    "                features[f'{axis}PEAK'] = np.mean(peak_times)\n",
    "            else:\n",
    "                features[f'{axis}PEAK'] = np.nan\n",
    "\n",
    "        # Cosine distances and correlations\n",
    "        for axes_pair in [('X', 'Y'), ('X', 'Z'), ('Y', 'Z')]:\n",
    "            ax1, ax2 = axes_pair\n",
    "            cos_distance = cosine(window[ax1], window[ax2])\n",
    "            features[f'{ax1}{ax2}COS'] = 0 if np.isnan(cos_distance) else cos_distance\n",
    "\n",
    "            corr, _ = pearsonr(window[ax1], window[ax2])\n",
    "            features[f'{ax1}{ax2}COR'] = corr\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "# Assuming A_concatenated_df is your DataFrame\n",
    "extracted_ACC_features = extract_ACC_features(A_concatenated_df)\n",
    "print(extracted_ACC_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID      XAVG  XABSOLDEV  XSTANDDEV      XVAR      XPEAK      YAVG  \\\n",
      "0      100669  0.065338   0.101305   0.133144  0.017727   9.777778 -0.035788   \n",
      "1      100669  0.007883   0.143982   0.187066  0.034994   8.363636  0.015595   \n",
      "2      100669 -0.009169   0.117488   0.143279  0.020529   9.100000 -0.019905   \n",
      "3      100669  0.076053   0.257138   0.402426  0.161946  10.875000  0.139601   \n",
      "4      100669 -0.012657   0.087577   0.116668  0.013611  12.285714 -0.243072   \n",
      "...       ...       ...        ...        ...       ...        ...       ...   \n",
      "17628  186676  0.003512   0.068154   0.088394  0.007813  10.111111 -0.010143   \n",
      "17629  186676 -0.004166   0.089045   0.112733  0.012709   9.111111 -0.000128   \n",
      "17630  186676  0.059700   0.056094   0.074168  0.005501   8.000000 -0.029557   \n",
      "17631  186676  0.057211   0.072314   0.088563  0.007843   8.888889  0.168358   \n",
      "17632  186676 -0.006753   0.054762   0.074504  0.005551   8.000000  0.015247   \n",
      "\n",
      "       YABSOLDEV  YSTANDDEV      YVAR  ...  ZABSOLDEV  ZSTANDDEV      ZVAR  \\\n",
      "0       0.095732   0.148417  0.022027  ...   0.130887   0.226732  0.051408   \n",
      "1       0.086900   0.109959  0.012091  ...   0.078700   0.097042  0.009417   \n",
      "2       0.081580   0.108649  0.011805  ...   0.057063   0.069046  0.004767   \n",
      "3       0.226978   0.354262  0.125501  ...   1.597758   1.845164  3.404630   \n",
      "4       0.210250   0.258421  0.066781  ...   0.070789   0.090040  0.008107   \n",
      "...          ...        ...       ...  ...        ...        ...       ...   \n",
      "17628   0.092597   0.116295  0.013525  ...   0.037319   0.046696  0.002181   \n",
      "17629   0.107375   0.134198  0.018009  ...   0.044726   0.055635  0.003095   \n",
      "17630   0.119741   0.166466  0.027711  ...   0.055476   0.065549  0.004297   \n",
      "17631   0.210385   0.243743  0.059411  ...   0.210355   0.293446  0.086111   \n",
      "17632   0.091288   0.126165  0.015918  ...   0.020211   0.026271  0.000690   \n",
      "\n",
      "           ZPEAK     XYCOS     XYCOR     XZCOS     XZCOR     YZCOS     YZCOR  \n",
      "0      10.875000  0.900631  0.232192  1.248194 -0.100805  0.822120  0.100324  \n",
      "1       7.250000  0.932403  0.062357  1.342729 -0.342131  0.970851  0.062108  \n",
      "2       9.333333  0.185665  0.817858  1.778810 -0.783473  1.714726 -0.734276  \n",
      "3       6.500000  1.109228 -0.193953  1.040404  0.115468  1.341138 -0.138003  \n",
      "4       8.300000  0.636674  0.399676  0.703461  0.326680  1.586116 -0.628757  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "17628   8.818182  0.656935  0.348105  0.708461  0.438113  0.354099  0.808322  \n",
      "17629   9.375000  0.975720  0.024261  1.007518 -0.030156  0.301911  0.806673  \n",
      "17630  12.428571  1.738780 -0.820295  1.792778 -0.626426  0.310932  0.852622  \n",
      "17631  13.000000  0.558869  0.192071  1.131793  0.155865  1.306871 -0.064093  \n",
      "17632   6.923077  0.924993  0.086817  1.387069 -0.531639  1.037644  0.036326  \n",
      "\n",
      "[17633 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def extract_GYRO_features(df, window_size=100):\n",
    "    # List to store feature dictionaries for each window\n",
    "    features_list = []\n",
    "\n",
    "    for start in range(0, len(df), window_size):\n",
    "        window = df.iloc[start:start + window_size]\n",
    "\n",
    "        # Ensure the window has the correct size\n",
    "        if len(window) < window_size:\n",
    "            continue\n",
    "\n",
    "        features = {}\n",
    "        features['ID'] = window['ID'].iloc[0]\n",
    "\n",
    "        for axis in ['X', 'Y', 'Z']:\n",
    "            axis_data = window[axis].values  # Convert to numpy array\n",
    "\n",
    "            # Calculate features\n",
    "            features[f'{axis}AVG'] = np.mean(axis_data)\n",
    "            features[f'{axis}ABSOLDEV'] = np.mean(np.abs(axis_data - np.mean(axis_data)))\n",
    "            features[f'{axis}STANDDEV'] = np.std(axis_data)\n",
    "            features[f'{axis}VAR'] = np.var(axis_data)\n",
    "\n",
    "            # Peak times\n",
    "            peaks, _ = find_peaks(axis_data)\n",
    "            if len(peaks) >= 2:\n",
    "                peak_times = np.diff(peaks)\n",
    "                features[f'{axis}PEAK'] = np.mean(peak_times)\n",
    "            else:\n",
    "                features[f'{axis}PEAK'] = np.nan\n",
    "\n",
    "        # Cosine distances and correlations\n",
    "        for axes_pair in [('X', 'Y'), ('X', 'Z'), ('Y', 'Z')]:\n",
    "            ax1, ax2 = axes_pair\n",
    "            cos_distance = cosine(window[ax1], window[ax2])\n",
    "            features[f'{ax1}{ax2}COS'] = 0 if np.isnan(cos_distance) else cos_distance\n",
    "\n",
    "            corr, _ = pearsonr(window[ax1], window[ax2])\n",
    "            features[f'{ax1}{ax2}COR'] = corr\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "# Assuming A_concatenated_df is your DataFrame\n",
    "extracted_GYRO_features = extract_GYRO_features(Gyroscope_df)\n",
    "print(extracted_GYRO_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistikal feechars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID      XAVG  XABSOLDEV  XSTANDDEV      XVAR     XPEAK      YAVG  \\\n",
      "0      100669  0.572234   0.038754   0.039080  0.001834  0.167726  0.866552   \n",
      "1      100669  0.550564   0.059721   0.060003  0.004060  0.151598  0.905964   \n",
      "2      100669  0.576616   0.052593   0.055080  0.003458  0.151842  0.884690   \n",
      "3      100669  0.125821   0.816523   0.756566  0.573894  0.189962  0.361579   \n",
      "4      100669  0.000000   0.075922   0.077304  0.006558  0.172924  0.099141   \n",
      "...       ...       ...        ...        ...       ...       ...       ...   \n",
      "17630  186676  0.536183   0.017634   0.017851  0.000462  0.039280  0.899528   \n",
      "17631  186676  0.540144   0.016888   0.018421  0.000487  0.072427  0.889690   \n",
      "17632  186676  0.540601   0.014863   0.015506  0.000365  0.066709  0.886531   \n",
      "17633  186676  0.509761   0.197260   0.207357  0.044338  0.167726  0.908531   \n",
      "17634  186676  0.401354   0.044116   0.050045  0.002892  0.123253  0.920114   \n",
      "\n",
      "       YABSOLDEV  YSTANDDEV      YVAR  ...  ZABSOLDEV  ZSTANDDEV      ZVAR  \\\n",
      "0       0.066717   0.072983  0.005847  ...   0.096127   0.098580  0.011073   \n",
      "1       0.060103   0.061802  0.004266  ...   0.198345   0.213386  0.048093   \n",
      "2       0.050284   0.048697  0.002728  ...   0.127938   0.140695  0.021638   \n",
      "3       1.000000   1.000000  1.000000  ...   0.325589   0.394814  0.159521   \n",
      "4       0.054403   0.057120  0.003677  ...   0.187239   0.185017  0.036530   \n",
      "...          ...        ...       ...  ...        ...        ...       ...   \n",
      "17630   0.028057   0.031251  0.001210  ...   0.100470   0.100368  0.011450   \n",
      "17631   0.030379   0.033778  0.001392  ...   0.091865   0.099797  0.011329   \n",
      "17632   0.021020   0.023729  0.000741  ...   0.062649   0.068764  0.005705   \n",
      "17633   0.039675   0.045968  0.002451  ...   0.096976   0.095560  0.010449   \n",
      "17634   0.014358   0.016418  0.000394  ...   0.069172   0.093022  0.009939   \n",
      "\n",
      "          ZPEAK     XYCOS     XYCOR     XZCOS     XZCOR     YZCOS     YZCOR  \n",
      "0      0.123653  0.681845  0.597705  0.688168  0.445772  0.001299  0.654190  \n",
      "1      0.165432  0.894819  0.392491  0.878159  0.596458  0.008548  0.305325  \n",
      "2      0.145654  0.545112  0.102577  0.503657  0.817302  0.004030  0.144159  \n",
      "3      0.183265  0.527766  0.994633  0.895879  0.572957  0.227750  0.631052  \n",
      "4      0.120713  0.036526  0.903942  0.990311  0.862260  0.979250  0.720538  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "17630  0.138089  0.992316  0.504882  0.992596  0.381804  0.001685  0.101520  \n",
      "17631  0.117970  0.990594  0.385906  0.987447  0.648476  0.001625  0.119635  \n",
      "17632  0.178077  0.992463  0.458399  0.991890  0.499907  0.000825  0.117852  \n",
      "17633  0.120713  0.849762  0.253719  0.839972  0.612434  0.001663  0.274369  \n",
      "17634  0.123457  0.997386  0.476147  0.996990  0.364200  0.001605  0.311883  \n",
      "\n",
      "[17635 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_Acc_features(df, id_column):\n",
    "    # Create a copy of the DataFrame to avoid changing the original data\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the ID column and store it separately\n",
    "    id_col = df_copy[[id_column]]\n",
    "\n",
    "    # Columns to be normalized (excluding the ID column)\n",
    "    columns_to_normalize = df_copy.drop(columns=[id_column]).columns\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the data\n",
    "    df_copy[columns_to_normalize] = scaler.fit_transform(df_copy[columns_to_normalize])\n",
    "\n",
    "    # Combine the ID column with the normalized data\n",
    "    df_normalized = pd.concat([id_col, df_copy[columns_to_normalize]], axis=1)\n",
    "\n",
    "    return df_normalized\n",
    "\n",
    "# Assuming extracted_ACC_features is your DataFrame and 'ID' is the ID column\n",
    "normalized_Acc_features = normalize_Acc_features(extracted_ACC_features, 'ID')\n",
    "print(normalized_Acc_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID      XAVG  XABSOLDEV  XSTANDDEV      XVAR     XPEAK      YAVG  \\\n",
      "0      100669  0.523442   0.093480   0.095237  0.009810  0.177585  0.550128   \n",
      "1      100669  0.478182   0.134782   0.135561  0.019383  0.135633  0.569574   \n",
      "2      100669  0.464749   0.109142   0.102816  0.011363  0.157478  0.556139   \n",
      "3      100669  0.531883   0.244291   0.296613  0.089771  0.210136  0.616504   \n",
      "4      100669  0.462001   0.080195   0.082916  0.007528  0.251987  0.471680   \n",
      "...       ...       ...        ...        ...       ...       ...       ...   \n",
      "17628  186676  0.474739   0.061398   0.061771  0.004313  0.187474  0.559833   \n",
      "17629  186676  0.468690   0.081615   0.079973  0.007028  0.157808  0.563623   \n",
      "17630  186676  0.519001   0.049727   0.051133  0.003031  0.124845  0.552486   \n",
      "17631  186676  0.517040   0.065424   0.061898  0.004330  0.151215  0.627387   \n",
      "17632  186676  0.466652   0.048438   0.051384  0.003059  0.124845  0.569442   \n",
      "\n",
      "       YABSOLDEV  YSTANDDEV      YVAR  ...  ZABSOLDEV  ZSTANDDEV      ZVAR  \\\n",
      "0       0.083160   0.102505  0.011082  ...   0.074850   0.107059  0.011686   \n",
      "1       0.075193   0.075130  0.006079  ...   0.044555   0.045148  0.002140   \n",
      "2       0.070393   0.074197  0.005934  ...   0.031995   0.031783  0.001082   \n",
      "3       0.201555   0.249035  0.063187  ...   0.926368   0.879660  0.774051   \n",
      "4       0.186465   0.180811  0.033618  ...   0.039963   0.041805  0.001842   \n",
      "...          ...        ...       ...  ...        ...        ...       ...   \n",
      "17628   0.080332   0.079640  0.006801  ...   0.020534   0.021114  0.000494   \n",
      "17629   0.093663   0.092384  0.009059  ...   0.024834   0.025381  0.000702   \n",
      "17630   0.104818   0.115354  0.013944  ...   0.031074   0.030114  0.000975   \n",
      "17631   0.186587   0.170363  0.029907  ...   0.120981   0.138907  0.019576   \n",
      "17632   0.079151   0.086665  0.008006  ...   0.010603   0.011364  0.000156   \n",
      "\n",
      "          ZPEAK     XYCOS     XYCOR     XZCOS     XZCOR     YZCOS     YZCOR  \n",
      "0      0.103170  0.449122  0.617474  0.635222  0.443532  0.416007  0.544789  \n",
      "1      0.049099  0.465173  0.531312  0.684222  0.319776  0.491522  0.525370  \n",
      "2      0.080174  0.087924  0.914600  0.910256  0.093449  0.869209  0.120709  \n",
      "3      0.037912  0.554504  0.401278  0.527518  0.554441  0.679527  0.423689  \n",
      "4      0.064761  0.315773  0.702444  0.352871  0.662754  0.803909  0.174326  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "17628  0.072490  0.326008  0.676280  0.355462  0.719898  0.178379  0.904540  \n",
      "17629  0.080796  0.487057  0.511985  0.510472  0.479762  0.151882  0.903701  \n",
      "17630  0.126343  0.872551  0.083516  0.917496  0.173986  0.156462  0.927049  \n",
      "17631  0.134866  0.276465  0.597120  0.574888  0.575157  0.662129  0.461244  \n",
      "17632  0.044222  0.461430  0.543721  0.707205  0.222594  0.525434  0.512270  \n",
      "\n",
      "[17633 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_Gyro_features(df, id_column):\n",
    "    # Create a copy of the DataFrame to avoid changing the original data\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the ID column and store it separately\n",
    "    id_col = df_copy[[id_column]]\n",
    "\n",
    "    # Columns to be normalized (excluding the ID column)\n",
    "    columns_to_normalize = df_copy.drop(columns=[id_column]).columns\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the data\n",
    "    df_copy[columns_to_normalize] = scaler.fit_transform(df_copy[columns_to_normalize])\n",
    "\n",
    "    # Combine the ID column with the normalized data\n",
    "    df_normalized = pd.concat([id_col, df_copy[columns_to_normalize]], axis=1)\n",
    "\n",
    "    return df_normalized\n",
    "\n",
    "# Assuming extracted_ACC_features is your DataFrame and 'ID' is the ID column\n",
    "normalized_Gyro_features = normalize_Gyro_features(extracted_GYRO_features, 'ID')\n",
    "print(normalized_Gyro_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalized_Acc_features = normalized_Acc_features[:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID      XAVG  XABSOLDEV  XSTANDDEV      XVAR     XPEAK      YAVG  \\\n",
      "0      100669  0.572234   0.038754   0.039080  0.001834  0.167726  0.866552   \n",
      "1      100669  0.550564   0.059721   0.060003  0.004060  0.151598  0.905964   \n",
      "2      100669  0.576616   0.052593   0.055080  0.003458  0.151842  0.884690   \n",
      "3      100669  0.125821   0.816523   0.756566  0.573894  0.189962  0.361579   \n",
      "4      100669  0.000000   0.075922   0.077304  0.006558  0.172924  0.099141   \n",
      "...       ...       ...        ...        ...       ...       ...       ...   \n",
      "17628  186676  0.528212   0.025916   0.023949  0.000764  0.056090  0.900217   \n",
      "17629  186676  0.530832   0.023037   0.024539  0.000797  0.057905  0.906228   \n",
      "17630  186676  0.536183   0.017634   0.017851  0.000462  0.039280  0.899528   \n",
      "17631  186676  0.540144   0.016888   0.018421  0.000487  0.072427  0.889690   \n",
      "17632  186676  0.540601   0.014863   0.015506  0.000365  0.066709  0.886531   \n",
      "\n",
      "       YABSOLDEV  YSTANDDEV      YVAR  ...  ZABSOLDEV  ZSTANDDEV      ZVAR  \\\n",
      "0       0.066717   0.072983  0.005847  ...   0.096127   0.098580  0.011073   \n",
      "1       0.060103   0.061802  0.004266  ...   0.198345   0.213386  0.048093   \n",
      "2       0.050284   0.048697  0.002728  ...   0.127938   0.140695  0.021638   \n",
      "3       1.000000   1.000000  1.000000  ...   0.325589   0.394814  0.159521   \n",
      "4       0.054403   0.057120  0.003677  ...   0.187239   0.185017  0.036530   \n",
      "...          ...        ...       ...  ...        ...        ...       ...   \n",
      "17628   0.026133   0.026904  0.000925  ...   0.124506   0.128401  0.018193   \n",
      "17629   0.026628   0.028637  0.001034  ...   0.091016   0.102183  0.011840   \n",
      "17630   0.028057   0.031251  0.001210  ...   0.100470   0.100368  0.011450   \n",
      "17631   0.030379   0.033778  0.001392  ...   0.091865   0.099797  0.011329   \n",
      "17632   0.021020   0.023729  0.000741  ...   0.062649   0.068764  0.005705   \n",
      "\n",
      "          ZPEAK     XYCOS     XYCOR     XZCOS     XZCOR     YZCOS     YZCOR  \n",
      "0      0.123653  0.681845  0.597705  0.688168  0.445772  0.001299  0.654190  \n",
      "1      0.165432  0.894819  0.392491  0.878159  0.596458  0.008548  0.305325  \n",
      "2      0.145654  0.545112  0.102577  0.503657  0.817302  0.004030  0.144159  \n",
      "3      0.183265  0.527766  0.994633  0.895879  0.572957  0.227750  0.631052  \n",
      "4      0.120713  0.036526  0.903942  0.990311  0.862260  0.979250  0.720538  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "17628  0.168350  0.991381  0.435028  0.987358  0.642743  0.002383  0.127298  \n",
      "17629  0.123457  0.989651  0.564176  0.990707  0.348907  0.001739  0.103314  \n",
      "17630  0.138089  0.992316  0.504882  0.992596  0.381804  0.001685  0.101520  \n",
      "17631  0.117970  0.990594  0.385906  0.987447  0.648476  0.001625  0.119635  \n",
      "17632  0.178077  0.992463  0.458399  0.991890  0.499907  0.000825  0.117852  \n",
      "\n",
      "[17633 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "normalized_Acc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID      XAVG  XABSOLDEV  XSTANDDEV      XVAR     XPEAK      YAVG  \\\n",
      "0      100669  0.572234   0.038754   0.039080  0.001834  0.167726  0.866552   \n",
      "1      100669  0.550564   0.059721   0.060003  0.004060  0.151598  0.905964   \n",
      "2      100669  0.576616   0.052593   0.055080  0.003458  0.151842  0.884690   \n",
      "3      100669  0.125821   0.816523   0.756566  0.573894  0.189962  0.361579   \n",
      "4      100669  0.000000   0.075922   0.077304  0.006558  0.172924  0.099141   \n",
      "...       ...       ...        ...        ...       ...       ...       ...   \n",
      "35261     NaN  0.474739   0.061398   0.061771  0.004313  0.187474  0.559833   \n",
      "35262     NaN  0.468690   0.081615   0.079973  0.007028  0.157808  0.563623   \n",
      "35263     NaN  0.519001   0.049727   0.051133  0.003031  0.124845  0.552486   \n",
      "35264     NaN  0.517040   0.065424   0.061898  0.004330  0.151215  0.627387   \n",
      "35265     NaN  0.466652   0.048438   0.051384  0.003059  0.124845  0.569442   \n",
      "\n",
      "       YABSOLDEV  YSTANDDEV      YVAR  ...  ZABSOLDEV  ZSTANDDEV      ZVAR  \\\n",
      "0       0.066717   0.072983  0.005847  ...   0.096127   0.098580  0.011073   \n",
      "1       0.060103   0.061802  0.004266  ...   0.198345   0.213386  0.048093   \n",
      "2       0.050284   0.048697  0.002728  ...   0.127938   0.140695  0.021638   \n",
      "3       1.000000   1.000000  1.000000  ...   0.325589   0.394814  0.159521   \n",
      "4       0.054403   0.057120  0.003677  ...   0.187239   0.185017  0.036530   \n",
      "...          ...        ...       ...  ...        ...        ...       ...   \n",
      "35261   0.080332   0.079640  0.006801  ...   0.020534   0.021114  0.000494   \n",
      "35262   0.093663   0.092384  0.009059  ...   0.024834   0.025381  0.000702   \n",
      "35263   0.104818   0.115354  0.013944  ...   0.031074   0.030114  0.000975   \n",
      "35264   0.186587   0.170363  0.029907  ...   0.120981   0.138907  0.019576   \n",
      "35265   0.079151   0.086665  0.008006  ...   0.010603   0.011364  0.000156   \n",
      "\n",
      "          ZPEAK     XYCOS     XYCOR     XZCOS     XZCOR     YZCOS     YZCOR  \n",
      "0      0.123653  0.681845  0.597705  0.688168  0.445772  0.001299  0.654190  \n",
      "1      0.165432  0.894819  0.392491  0.878159  0.596458  0.008548  0.305325  \n",
      "2      0.145654  0.545112  0.102577  0.503657  0.817302  0.004030  0.144159  \n",
      "3      0.183265  0.527766  0.994633  0.895879  0.572957  0.227750  0.631052  \n",
      "4      0.120713  0.036526  0.903942  0.990311  0.862260  0.979250  0.720538  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "35261  0.072490  0.326008  0.676280  0.355462  0.719898  0.178379  0.904540  \n",
      "35262  0.080796  0.487057  0.511985  0.510472  0.479762  0.151882  0.903701  \n",
      "35263  0.126343  0.872551  0.083516  0.917496  0.173986  0.156462  0.927049  \n",
      "35264  0.134866  0.276465  0.597120  0.574888  0.575157  0.662129  0.461244  \n",
      "35265  0.044222  0.461430  0.543721  0.707205  0.222594  0.525434  0.512270  \n",
      "\n",
      "[35266 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concatenate_in_chunks(df1, df2, chunk_size=10000):\n",
    "    concatenated_dfs = []\n",
    "\n",
    "    for start in range(0, len(df1), chunk_size):\n",
    "        end = min(start + chunk_size, len(df1))\n",
    "        chunk1 = df1.iloc[start:end]\n",
    "        chunk2 = df2.iloc[start:end]\n",
    "\n",
    "        concatenated_chunk = pd.merge(chunk1, chunk2.drop(columns='ID'), how='outer')\n",
    "        concatenated_dfs.append(concatenated_chunk)\n",
    "\n",
    "    return pd.concat(concatenated_dfs, ignore_index=True)\n",
    "\n",
    "concatenated_df = concatenate_in_chunks(normalized_Acc_features, normalized_Gyro_features)\n",
    "print(concatenated_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID      XAVG  XABSOLDEV  XSTANDDEV      XVAR     XPEAK      YAVG  \\\n",
      "0      100669  0.572234   0.038754   0.039080  0.001834  0.167726  0.866552   \n",
      "1      100669  0.550564   0.059721   0.060003  0.004060  0.151598  0.905964   \n",
      "2      100669  0.576616   0.052593   0.055080  0.003458  0.151842  0.884690   \n",
      "3      100669  0.125821   0.816523   0.756566  0.573894  0.189962  0.361579   \n",
      "4      100669  0.000000   0.075922   0.077304  0.006558  0.172924  0.099141   \n",
      "...       ...       ...        ...        ...       ...       ...       ...   \n",
      "35261     NaN  0.474739   0.061398   0.061771  0.004313  0.187474  0.559833   \n",
      "35262     NaN  0.468690   0.081615   0.079973  0.007028  0.157808  0.563623   \n",
      "35263     NaN  0.519001   0.049727   0.051133  0.003031  0.124845  0.552486   \n",
      "35264     NaN  0.517040   0.065424   0.061898  0.004330  0.151215  0.627387   \n",
      "35265     NaN  0.466652   0.048438   0.051384  0.003059  0.124845  0.569442   \n",
      "\n",
      "       YABSOLDEV  YSTANDDEV      YVAR  ...  ZABSOLDEV  ZSTANDDEV      ZVAR  \\\n",
      "0       0.066717   0.072983  0.005847  ...   0.096127   0.098580  0.011073   \n",
      "1       0.060103   0.061802  0.004266  ...   0.198345   0.213386  0.048093   \n",
      "2       0.050284   0.048697  0.002728  ...   0.127938   0.140695  0.021638   \n",
      "3       1.000000   1.000000  1.000000  ...   0.325589   0.394814  0.159521   \n",
      "4       0.054403   0.057120  0.003677  ...   0.187239   0.185017  0.036530   \n",
      "...          ...        ...       ...  ...        ...        ...       ...   \n",
      "35261   0.080332   0.079640  0.006801  ...   0.020534   0.021114  0.000494   \n",
      "35262   0.093663   0.092384  0.009059  ...   0.024834   0.025381  0.000702   \n",
      "35263   0.104818   0.115354  0.013944  ...   0.031074   0.030114  0.000975   \n",
      "35264   0.186587   0.170363  0.029907  ...   0.120981   0.138907  0.019576   \n",
      "35265   0.079151   0.086665  0.008006  ...   0.010603   0.011364  0.000156   \n",
      "\n",
      "          ZPEAK     XYCOS     XYCOR     XZCOS     XZCOR     YZCOS     YZCOR  \n",
      "0      0.123653  0.681845  0.597705  0.688168  0.445772  0.001299  0.654190  \n",
      "1      0.165432  0.894819  0.392491  0.878159  0.596458  0.008548  0.305325  \n",
      "2      0.145654  0.545112  0.102577  0.503657  0.817302  0.004030  0.144159  \n",
      "3      0.183265  0.527766  0.994633  0.895879  0.572957  0.227750  0.631052  \n",
      "4      0.120713  0.036526  0.903942  0.990311  0.862260  0.979250  0.720538  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "35261  0.072490  0.326008  0.676280  0.355462  0.719898  0.178379  0.904540  \n",
      "35262  0.080796  0.487057  0.511985  0.510472  0.479762  0.151882  0.903701  \n",
      "35263  0.126343  0.872551  0.083516  0.917496  0.173986  0.156462  0.927049  \n",
      "35264  0.134866  0.276465  0.597120  0.574888  0.575157  0.662129  0.461244  \n",
      "35265  0.044222  0.461430  0.543721  0.707205  0.222594  0.525434  0.512270  \n",
      "\n",
      "[35266 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package])\n",
    "\n",
    "# Update scikit-learn, numpy, pandas, and threadpoolctl\n",
    "install(\"scikit-learn\")\n",
    "install(\"numpy\")\n",
    "install(\"pandas\")\n",
    "install(\"threadpoolctl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average KNN Accuracy: 0.7863635304281438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'concatenated_df' is your DataFrame\n",
    "X = concatenated_df.drop('ID', axis=1)  # Features\n",
    "y = concatenated_df['ID']  # Labels\n",
    "\n",
    "# Remove rows with NaN values in both features and labels\n",
    "non_nan_indices = X.dropna().index.intersection(y.dropna().index)\n",
    "X_clean = X.loc[non_nan_indices]\n",
    "y_clean = y.loc[non_nan_indices]\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=25, shuffle=True, random_state=42)\n",
    "knn_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_clean):\n",
    "    X_train, X_test = X_clean.iloc[train_index], X_clean.iloc[test_index]\n",
    "    y_train, y_test = y_clean.iloc[train_index], y_clean.iloc[test_index]\n",
    "\n",
    "    # Initialize KNN, fit on training data, and make predictions\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)  # You can change the number of neighbors\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and append to list\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    knn_accuracies.append(accuracy)\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "average_accuracy = np.mean(knn_accuracies)\n",
    "print(f'Average KNN Accuracy: {average_accuracy}')\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = concatenated_df.drop('ID', axis=1)  \n",
    "y = concatenated_df['ID'] \n",
    "\n",
    "X_trainf, X_testf, y_trainf, y_testf = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8658674508029858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X_trainf, y_trainf, X_testf, y_testf are defined\n",
    "\n",
    "# Remove rows with NaN values in features and corresponding labels for the training set\n",
    "train_mask = X_trainf.isna().any(axis=1) | y_trainf.isna()\n",
    "X_trainf_clean = X_trainf[~train_mask]\n",
    "y_trainf_clean = y_trainf[~train_mask]\n",
    "\n",
    "# Remove rows with NaN values in features and corresponding labels for the testing set\n",
    "test_mask = X_testf.isna().any(axis=1) | y_testf.isna()\n",
    "X_testf_clean = X_testf[~test_mask]\n",
    "y_testf_clean = y_testf[~test_mask]\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the model using the training sets without NaN values\n",
    "rf_classifier.fit(X_trainf_clean, y_trainf_clean)\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred_rf = rf_classifier.predict(X_testf_clean)\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy_rf = accuracy_score(y_testf_clean, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Convert feature data to numeric and handle NaNs\n",
    "X_trainf_clean = X_trainf.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "X_testf_clean = X_testf.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Convert labels to numeric if necessary\n",
    "y_trainf_numeric = pd.to_numeric(y_trainf, errors='coerce').fillna(0)\n",
    "\n",
    "# Create a pipeline with data scaling and SVM classifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__kernel': ['linear', 'rbf'],\n",
    "    'svm__gamma': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_trainf_clean, y_trainf_numeric)\n",
    "\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best estimator\n",
    "y_predf = best_svm_classifier.predict(X_testf_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 0.9570148576613361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming y_testf is the true labels for your test dataset\n",
    "y_testf_numeric = pd.to_numeric(y_testf, errors='coerce').fillna(0)\n",
    "\n",
    "# Predict using the best estimator\n",
    "y_predf = best_svm_classifier.predict(X_testf_clean)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_testf_numeric, y_predf)\n",
    "print(\"SVM Classifier Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
